var syncUtil = require('./util');
var debug = syncUtil.debug;
var debugError = syncUtil.debugError;
var metrics = require('./sync-metrics');
var util = require('util');
var async = require('async');

var syncStorage, dataHandlers, hashProvider, metricsClient;

//TODO: move this to the storage.js file
var SYNC_UPDATE_TYPES = {
  APPLIED: 'applied',
  FAILED: 'failed',
  COLLISION: 'collisions'
};

function saveUpdate(datasetId, pendingChange, type, msg, callback) {
  var syncUpdateFields = {
    type: type,
    cuid: pendingChange.cuid,
    action: pendingChange.action,
    hash: pendingChange.hash,
    uid: pendingChange.uid,
    msg: msg,
    timestamp: Date.now()
  };
  if (pendingChange.oldUid) {
    syncUpdateFields.oldUid = pendingChange.oldUid;
  }
  syncStorage.saveUpdate(datasetId, syncUpdateFields, callback);
}

function handleCollision(datasetId, metaData, pendingChange, dataHash, callback) {
  var collisionFields = {
    uid: pendingChange.uid,
    hash: dataHash,
    pre: pendingChange.pre,
    post: pendingChange.post,
    timestamp: pendingChange.timestamp
  };
  var newCollisionCount = pendingChange.datasetClient.collisionCount + 1;
  syncStorage.updateDatasetClient(pendingChange.datasetClient.id, {collisionCount: newCollisionCount}, function(err) {
    if (err) {
      debugError('[%s] Updating dataset client collision count (%s) failed : err = %j', datasetId, pendingChange.datasetClient.id, err);
    }
  });
  dataHandlers.handleCollision(datasetId, collisionFields.hash, collisionFields.timestamp, collisionFields.uid, collisionFields.pre, collisionFields.post, metaData, callback);
}

/**
 * Create the given pending change in the backend.
 * It will always create the record in the backend.
 * @param {String} datasetId the dataset id
 * @param {Object} pendingChange the pending change. It should have the following fields
 * @param {String} pendingChange.datasetId the dataset id of the pending change
 * @param {Object} pendingChange.meta_data the meta_data of the dataset
 * @param {String} pendingChange.action the action of the pending change, should be "create"
 * @param {String} pendingChange.uid the unique id of the data record. This is a temp uid generated by the client and should be replaced by the real uid once the record is created.
 * @param {String} pendingChange.cuid the unique client id of the client device
 * @param {String} pendingChange.hash a unique id of the pending change, normally it is a hash value generated from the content of the pendingChange object
 * @param {Object} pendingChange.post the record after change
 * @param {Function} callback
 */
function doCreate(datasetId, pendingChange, callback) {
  var record = pendingChange.post;
  var metaData = pendingChange.meta_data;
  debug('[%s] CREATE Start data = %j', datasetId, record);
  var tasks = [];
  dataHandlers.doCreate(datasetId, record, metaData, function(err, data) {
    if (err) {
      debugError('[%s] CREATE Failed - : err = %j', datasetId, err);
    } else {
      debug('[%s] CREATE Success - uid = %s', datasetId, data.uid);
      pendingChange.oldUid = pendingChange.uid;
      pendingChange.uid = data.uid;
      if (pendingChange.oldUid !== data.uid) {
        tasks.push(function(cb){
          syncStorage.saveRecordUidMapping(datasetId, pendingChange.oldUid, data.uid, cb);
        });
      }
    }
    tasks.push(function(cb){
      saveUpdate(datasetId, pendingChange, err ? SYNC_UPDATE_TYPES.FAILED : SYNC_UPDATE_TYPES.APPLIED, err ? util.inspect(err) : null, cb);
    });

    return async.series(tasks, callback);
  });
}

/**
 * Update the given pending change in the backend.
 * It will only update the record if the hash value of the `pre` record matches the hash value of the record from backend.
 * Otherwise the change is either already applied, or a collision will be generated.
 * @param {String} datasetId the dataset id
 * @param {Object} pendingChange the pending change. It should have the following fields
 * @param {String} pendingChange.datasetId the dataset id of the pending change
 * @param {Object} pendingChange.meta_data the meta_data of the dataset
 * @param {String} pendingChange.action the action of the pending change, should be "update"
 * @param {String} pendingChange.uid the unique id of the data record
 * @param {String} pendingChange.cuid the unique client id of the client device
 * @param {String} pendingChange.hash a unique id of the pending change, normally it is a hash value generated from the content of the pendingChange object
 * @param {Object} pendingChange.pre the record before change.
 * @param {Object} pendingChange.post the record after change
 * @param {Function} callback
 */
function doUpdate(datasetId, pendingChange, callback) {
  debug('[%s] UPDATE Start', datasetId);
  var metaData = pendingChange.meta_data;
  var uid = pendingChange.uid;
  dataHandlers.doRead(datasetId, uid, metaData, function(err, data) {
    if (err) {
      debugError('[%s] READ for UPDATE Failed - uid = %s : err = %j', datasetId, uid, err);
      return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.FAILED, util.inspect(err), callback);
    }
    debug('[%s] READ for UPDATE Success', datasetId);
    debug('[%s] READ for UPDATE Data : \n%j', datasetId, data);

    var preHash = hashProvider.recordHash(datasetId, pendingChange.pre);
    var dataHash = hashProvider.recordHash(datasetId, data);

    debug('[%s] UPDATE Hash Check %s (client :: dataStore) = %s :: ' + dataHash, datasetId, uid, preHash);

    if (preHash === dataHash) {
      dataHandlers.doUpdate(datasetId, uid, pendingChange.post, metaData, function(err) {
        if (err) {
          debugError('[%s] UPDATE Failed - uid = %s : err = %j', datasetId, uid, err);
        } else {
          debug('[%s] UPDATE Success - uid = %s : hash = %s', datasetId, uid, dataHash);
        }
        return saveUpdate(datasetId, pendingChange, err ? SYNC_UPDATE_TYPES.FAILED : SYNC_UPDATE_TYPES.APPLIED, err ? util.inspect(err) : null, callback);
      });
    } else {
      var postHash = hashProvider.recordHash(datasetId, pendingChange.post);
      if (postHash === dataHash) {
        // Update has already been applied
        debug('[%s] UPDATE Already Applied - uid = %s : hash = %s', datasetId, uid, dataHash);
        return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.APPLIED, null, callback);
      }
      else {
        debug('[%s] UPDATE COLLISION \n Pre record from client:\n%j\nCurrent record from data store:\n%j', datasetId, syncUtil.sortObject(pendingChange.pre), syncUtil.sortObject(data));
        handleCollision(datasetId, metaData, pendingChange, dataHash, function(err) {
          if (err) {
            debugError('[%s] Failed to save collision uid = %s : err = %j', datasetId, uid, err);
          }
          return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.COLLISION, null, callback);
        });
      }
    }
  });
}

/**
 * Delete the given pending change from the backend.
 * It will only delete the record if the hash value of the `pre` record matches the hash value of the record from backend.
 * Otherwise the change is either already applied, or a collision will be generated.
 * @param {String} datasetId the dataset id
 * @param {Object} pendingChange the pending change. It should have the following fields
 * @param {String} pendingChange.datasetId the dataset id of the pending change
 * @param {Object} pendingChange.meta_data the meta_data of the dataset
 * @param {String} pendingChange.action the action of the pending change, should be "delete"
 * @param {String} pendingChange.uid the unique id of the data record
 * @param {String} pendingChange.cuid the unique client id of the client device
 * @param {String} pendingChange.hash a unique id of the pending change, normally it is a hash value generated from the content of the pendingChange object
 * @param {Object} pendingChange.pre the record before change.
 * @param {Function} callback
 */
function doDelete(datasetId, pendingChange, callback) {
  debug('[%s] DELETE Start', datasetId);
  var metaData = pendingChange.meta_data;
  var uid = pendingChange.uid;
  dataHandlers.doRead(datasetId, uid, metaData, function(err, data) {
    if (err) {
      debugError('READ for DELETE Failed - uid = %s : err = %j', datasetId, uid, err);
      return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.FAILED, util.inspect(err), callback);
    }
    debug('[%s] READ for DELETE Success', datasetId);
    debug('[%s] READ for DELETE Data : \n%j', datasetId, data);

    var preHash = hashProvider.recordHash(datasetId, pendingChange.pre);
    var dataHash = hashProvider.recordHash(datasetId, data);

    debug('[%s] DELETE Hash Check %s (client :: dataStore) = %s :: %s', datasetId, uid, preHash.dataHash);

    if (!dataHash) {
      //record has already been deleted
      debug('[%s] DELETE Already performed - uid=%s', datasetId, uid);
      return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.APPLIED, null, callback);
    }
    else {
      if (preHash === dataHash) {
        dataHandlers.doDelete(datasetId, uid, metaData, function(err) {
          if (err) {
            debugError('[%s] DELETE Failed - uid=%s : err = %j', datasetId, err);
          } else {
            debug('[%s] DELETE Success - uid=%s : hash = %s', datasetId, dataHash);
          }
          return saveUpdate(datasetId, pendingChange, err ? SYNC_UPDATE_TYPES.FAILED : SYNC_UPDATE_TYPES.APPLIED, err ? util.inspect(err) : null, callback);
        });
      } else {
        debug('[%s] DELETE COLLISION \n Pre record from client:\n%j\nCurrent record from data store:\n%j', datasetId, syncUtil.sortObject(pendingChange.pre), syncUtil.sortObject(data));
        handleCollision(datasetId, metaData, pendingChange, dataHash, function(err) {
          if (err) {
            debugError('[%s] Failed to save collision uid = %s : err = %j', datasetId, err);
          }
          return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.COLLISION, null, callback);
        });
      }
    }
  });
}

function replaceUidIfRequired(datasetId, pendingChange, callback) {
  syncStorage.lookupRecordUidByClientUid(datasetId, pendingChange.uid, function(err, serverUid){
    if (err) {
      debugError('[%s] Failed to look up recordUid due to error %j', datasetId, err);
    }
    if (serverUid) {
      debug('[%s] replacing pendingChange uid from %s to %s', pendingChange.uid, serverUid);
      pendingChange.uid = serverUid;
    }
    //even if there is an error, we can still try to apply the change.
    return callback();
  });
}

/**
 * apply the given pending change to the backend using the dataHandlers
 * @param {Object} pendingChange the pending change object
 * @param {String} pendingChange.datasetId the dataset id of the pending change
 * @param {Object} pendingChange.meta_data the meta_data of the dataset
 * @param {String} pendingChange.action the action of the pending change, should be one of "create", "update" or "delete"
 * @param {String} pendingChange.uid the unique id of the data record
 * @param {String} pendingChange.cuid the unique client id of the client device
 * @param {String} pendingChange.hash a unique id of the pending change, normally it is a hash value generated from the content of the pendingChange object
 * @param {Object} pendingChange.pre the record before change. Optional.
 * @param {Object} pendingChange.post the record after change. Optional.
 * @param {Number} tries a counter to record how many times the given pending change has been executed
 * @param {Function} callback the callback function
 * @returns
 */
function applyPendingChange(pendingChange, tries, callback) {
  var datasetId = pendingChange.datasetId;
  if (!datasetId || !pendingChange.action || !pendingChange.uid || !pendingChange.cuid || !pendingChange.hash) {
    debugError("[%s] invalid pendingChange request dropped :: item = %j", datasetId, pendingChange);
    return callback();
  }
  debug('[%s] processPending :: item = %j', datasetId, pendingChange);
  if (tries > 1) {
    //the pendingChange has been processed before but it didn't complete, most likely the process crashedd. Mark it as failed
    debugError('[%s] processPending failed :: tries = %d  :: item = %j', datasetId, tries, pendingChange);
    return saveUpdate(datasetId, pendingChange, SYNC_UPDATE_TYPES.FAILED, "crashed", callback);
  }
  var action = pendingChange.action.toLowerCase();
  var timer = metrics.startTimer();

  function onComplete(err) {
    metricsClient.gauge(metrics.KEYS.PENDING_CHANGE_PROCESS_TIME, {success: !err, action: action}, timer.stop());
    return callback(err);
  }

  switch (action) {
    case "create":
      doCreate(datasetId, pendingChange, onComplete);
      break;
    case "update":
      async.series([
        function(cb) {
          replaceUidIfRequired(datasetId, pendingChange, cb);
        },
        function(cb) {
          doUpdate(datasetId, pendingChange, cb);
        }
      ], onComplete);
      break;
    case "delete":
      async.series([
        function(cb) {
          replaceUidIfRequired(datasetId, pendingChange, cb);
        },
        function(cb) {
          doDelete(datasetId, pendingChange, cb);
        }
      ], onComplete);
      break;
    default:
      debugError("[%s] invalid pendingChange request dropped :: item = %j", datasetId, pendingChange);
      return onComplete();
  }
}

module.exports = function(syncStorageImpl, dataHandlersImpl, hashProviderImpl, metricsClientImpl) {
  syncStorage = syncStorageImpl;
  dataHandlers = dataHandlersImpl;
  hashProvider = hashProviderImpl;
  metricsClient = metricsClientImpl;
  return function(pendingChangeRequest, callback) {
    var pendingChange = pendingChangeRequest.payload;
    var tries = pendingChangeRequest.tries;
    return applyPendingChange(pendingChange, tries, callback);
  }
};

module.exports.SYNC_UPDATE_TYPES = SYNC_UPDATE_TYPES;
